{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theodore/miniconda3/envs/vasr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "split = 'train'\n",
    "\n",
    "src_dir = '/media/theodore/TRANSCEND/data/vietnamese-speaker-lip-clip'\n",
    "src_metadata_dir = os.path.join(src_dir, 'metadata')\n",
    "src_visual_dir = os.path.join(src_dir, 'visual')\n",
    "\n",
    "dest_dir = '/media/theodore/TRANSCEND/data/vasr'\n",
    "dest_old_metadata_dir = os.path.join(dest_dir, 'metadata')\n",
    "dest_new_metadata_dir = os.path.join(dest_dir, 'pretrain')\n",
    "dest_visual_dir = os.path.join(dest_dir, 'visual')\n",
    "dest_audio_dir = os.path.join(dest_dir, 'audio')\n",
    "\n",
    "train_ratio, val_ratio, test_ratio = 0.8, 0.1, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>channel</th>\n",
       "      <th>duration</th>\n",
       "      <th>fps</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000</td>\n",
       "      <td>behomethansohoc7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>728521255754192000100000-0-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000001</td>\n",
       "      <td>behomethansohoc7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>728521255754192000100000-2-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000002</td>\n",
       "      <td>behomethansohoc7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>728521255754192000100000-4-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000003</td>\n",
       "      <td>behomethansohoc7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>728521255754192000100000-6-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000004</td>\n",
       "      <td>behomethansohoc7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>728521255754192000100000-8-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282237</th>\n",
       "      <td>1282237</td>\n",
       "      <td>vietrilieu1006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>730153677436544948000008-0-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282238</th>\n",
       "      <td>1282238</td>\n",
       "      <td>vietrilieu1006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>730153677436544948000009-2-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282239</th>\n",
       "      <td>1282239</td>\n",
       "      <td>vietrilieu1006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>730153677436544948000009-4-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282240</th>\n",
       "      <td>1282240</td>\n",
       "      <td>vietrilieu1006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>730153677436544948000004-0-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282241</th>\n",
       "      <td>1282241</td>\n",
       "      <td>vietrilieu1006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>726978691028384487000018-0-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1282242 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id           channel  duration  fps  sampling_rate  \\\n",
       "0        0000000  behomethansohoc7       3.0   25          16000   \n",
       "1        0000001  behomethansohoc7       3.0   25          16000   \n",
       "2        0000002  behomethansohoc7       3.0   25          16000   \n",
       "3        0000003  behomethansohoc7       3.0   25          16000   \n",
       "4        0000004  behomethansohoc7       3.0   25          16000   \n",
       "...          ...               ...       ...  ...            ...   \n",
       "1282237  1282237    vietrilieu1006       3.0   25          16000   \n",
       "1282238  1282238    vietrilieu1006       3.0   25          16000   \n",
       "1282239  1282239    vietrilieu1006       3.0   25          16000   \n",
       "1282240  1282240    vietrilieu1006       3.0   25          16000   \n",
       "1282241  1282241    vietrilieu1006       3.0   25          16000   \n",
       "\n",
       "                                 video  \n",
       "0         728521255754192000100000-0-3  \n",
       "1         728521255754192000100000-2-5  \n",
       "2         728521255754192000100000-4-7  \n",
       "3         728521255754192000100000-6-9  \n",
       "4        728521255754192000100000-8-11  \n",
       "...                                ...  \n",
       "1282237   730153677436544948000008-0-3  \n",
       "1282238   730153677436544948000009-2-5  \n",
       "1282239   730153677436544948000009-4-7  \n",
       "1282240   730153677436544948000004-0-3  \n",
       "1282241   726978691028384487000018-0-3  \n",
       "\n",
       "[1282242 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_files = os.listdir(dest_old_metadata_dir)\n",
    "channel_num_samples = {\n",
    "    metadata_file: pd.read_parquet(os.path.join(dest_old_metadata_dir, metadata_file)).shape[0]\n",
    "    for metadata_file in metadata_files\n",
    "}\n",
    "channel_num_samples = {k: v for k, v in sorted(channel_num_samples.items(), key=lambda item: item[1], reverse=True)}\n",
    "old_df = pd.concat([pd.read_parquet(os.path.join(dest_old_metadata_dir, metadata_file)) for metadata_file in channel_num_samples.keys()], ignore_index=True)\n",
    "old_df['video'] = old_df['id']\n",
    "old_df['id'] = old_df.index.map(lambda x: f'{x:07d}')\n",
    "old_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fps</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>transcript</th>\n",
       "      <th>shard</th>\n",
       "      <th>video_num_frames</th>\n",
       "      <th>audio_num_frames</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0264850</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>bất cứ một chút thu hút nào cả có nghĩa rằng là</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>48000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1249460</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>độ từ vựng gần như cao nhất trong sử dụng tiến...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>48000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1225299</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>khi mà mình bắt đầu làm các vi đi ô hay là mìn...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>48000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1039184</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>kỳ kỳ cầm một cái sản phẩm kỳ không có bỏ tiền...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>48000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0406289</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>em gặp rất là nhiều đối tượng và không có phân...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>48000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128205</th>\n",
       "      <td>0220647</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>tử tế niềm vui và hạnh phúc đến với</td>\n",
       "      <td>1283</td>\n",
       "      <td>76</td>\n",
       "      <td>48000</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128206</th>\n",
       "      <td>0220804</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>hoài là không có ai quan tâm đến bạn ngoài anh ta</td>\n",
       "      <td>1283</td>\n",
       "      <td>76</td>\n",
       "      <td>48000</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128207</th>\n",
       "      <td>0194363</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>làm mẹ nhưng vẫn chưa được ở ngoài ấy rất nhiều</td>\n",
       "      <td>1283</td>\n",
       "      <td>76</td>\n",
       "      <td>48000</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128208</th>\n",
       "      <td>0139143</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>đang kết kỉnh giống như ở trên trang đứa phân ...</td>\n",
       "      <td>1283</td>\n",
       "      <td>76</td>\n",
       "      <td>48000</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128209</th>\n",
       "      <td>0176997</td>\n",
       "      <td>25</td>\n",
       "      <td>16000</td>\n",
       "      <td>dậy rồi kia đi lại được á em hiền ăn sinh mổ t...</td>\n",
       "      <td>1283</td>\n",
       "      <td>76</td>\n",
       "      <td>48000</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1282242 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  fps  sampling_rate  \\\n",
       "0       0264850   25          16000   \n",
       "1       1249460   25          16000   \n",
       "2       1225299   25          16000   \n",
       "3       1039184   25          16000   \n",
       "4       0406289   25          16000   \n",
       "...         ...  ...            ...   \n",
       "128205  0220647   25          16000   \n",
       "128206  0220804   25          16000   \n",
       "128207  0194363   25          16000   \n",
       "128208  0139143   25          16000   \n",
       "128209  0176997   25          16000   \n",
       "\n",
       "                                               transcript  shard  \\\n",
       "0         bất cứ một chút thu hút nào cả có nghĩa rằng là      1   \n",
       "1       độ từ vựng gần như cao nhất trong sử dụng tiến...      1   \n",
       "2       khi mà mình bắt đầu làm các vi đi ô hay là mìn...      1   \n",
       "3       kỳ kỳ cầm một cái sản phẩm kỳ không có bỏ tiền...      1   \n",
       "4       em gặp rất là nhiều đối tượng và không có phân...      1   \n",
       "...                                                   ...    ...   \n",
       "128205                tử tế niềm vui và hạnh phúc đến với   1283   \n",
       "128206  hoài là không có ai quan tâm đến bạn ngoài anh ta   1283   \n",
       "128207    làm mẹ nhưng vẫn chưa được ở ngoài ấy rất nhiều   1283   \n",
       "128208  đang kết kỉnh giống như ở trên trang đứa phân ...   1283   \n",
       "128209  dậy rồi kia đi lại được á em hiền ăn sinh mổ t...   1283   \n",
       "\n",
       "        video_num_frames  audio_num_frames  split  \n",
       "0                     76             48000  train  \n",
       "1                     76             48000  train  \n",
       "2                     76             48000  train  \n",
       "3                     76             48000  train  \n",
       "4                     76             48000  train  \n",
       "...                  ...               ...    ...  \n",
       "128205                76             48000    val  \n",
       "128206                76             48000    val  \n",
       "128207                76             48000    val  \n",
       "128208                76             48000    val  \n",
       "128209                76             48000    val  \n",
       "\n",
       "[1282242 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for split in ['train', 'test', 'val']:\n",
    "    split_df = pd.read_parquet(os.path.join(dest_new_metadata_dir, f'{split}_completed.parquet'))\n",
    "    split_df['split'] = pd.Series([split] * len(split_df))\n",
    "    dfs.append(split_df)\n",
    "new_df = pd.concat(dfs)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>shard</th>\n",
       "      <th>channel</th>\n",
       "      <th>video</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0264850</td>\n",
       "      <td>1</td>\n",
       "      <td>laihofficial</td>\n",
       "      <td>713610947467836137000000-50-53</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1249460</td>\n",
       "      <td>1</td>\n",
       "      <td>dr.hieuielts</td>\n",
       "      <td>722709729912458778100000-18-21</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1225299</td>\n",
       "      <td>1</td>\n",
       "      <td>bahuy.henry</td>\n",
       "      <td>728901091546110694600007-0-3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1039184</td>\n",
       "      <td>1</td>\n",
       "      <td>unofficiallykyky</td>\n",
       "      <td>729115300077145625800005-7-10</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0406289</td>\n",
       "      <td>1</td>\n",
       "      <td>cohoichoai</td>\n",
       "      <td>703184817938137421000010-1-4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282237</th>\n",
       "      <td>0220647</td>\n",
       "      <td>1283</td>\n",
       "      <td>lifecoachtuean</td>\n",
       "      <td>726858208965252224200001-40-43</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282238</th>\n",
       "      <td>0220804</td>\n",
       "      <td>1283</td>\n",
       "      <td>lifecoachtuean</td>\n",
       "      <td>703374814094352716900000-29-32</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282239</th>\n",
       "      <td>0194363</td>\n",
       "      <td>1283</td>\n",
       "      <td>tamtinhmebim.mcv</td>\n",
       "      <td>718576990105792025800037-2-5</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282240</th>\n",
       "      <td>0139143</td>\n",
       "      <td>1283</td>\n",
       "      <td>genz.justdoit</td>\n",
       "      <td>725146313466005427300000-2-5</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282241</th>\n",
       "      <td>0176997</td>\n",
       "      <td>1283</td>\n",
       "      <td>tamtinhmebim.mcv</td>\n",
       "      <td>724812743278656230600039-2-5</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1282242 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  shard           channel                           video  \\\n",
       "0        0264850      1      laihofficial  713610947467836137000000-50-53   \n",
       "1        1249460      1      dr.hieuielts  722709729912458778100000-18-21   \n",
       "2        1225299      1       bahuy.henry    728901091546110694600007-0-3   \n",
       "3        1039184      1  unofficiallykyky   729115300077145625800005-7-10   \n",
       "4        0406289      1        cohoichoai    703184817938137421000010-1-4   \n",
       "...          ...    ...               ...                             ...   \n",
       "1282237  0220647   1283    lifecoachtuean  726858208965252224200001-40-43   \n",
       "1282238  0220804   1283    lifecoachtuean  703374814094352716900000-29-32   \n",
       "1282239  0194363   1283  tamtinhmebim.mcv    718576990105792025800037-2-5   \n",
       "1282240  0139143   1283     genz.justdoit    725146313466005427300000-2-5   \n",
       "1282241  0176997   1283  tamtinhmebim.mcv    724812743278656230600039-2-5   \n",
       "\n",
       "         split  \n",
       "0        train  \n",
       "1        train  \n",
       "2        train  \n",
       "3        train  \n",
       "4        train  \n",
       "...        ...  \n",
       "1282237    val  \n",
       "1282238    val  \n",
       "1282239    val  \n",
       "1282240    val  \n",
       "1282241    val  \n",
       "\n",
       "[1282242 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df = pd.merge(new_df, old_df, how='left', on='id')\n",
    "joined_df = joined_df[['id', 'shard', 'channel', 'video', 'split']]\n",
    "joined_df.to_parquet('mapping.parquet')\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>shard</th>\n",
       "      <th>channel</th>\n",
       "      <th>video</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1175269</th>\n",
       "      <td>0140186</td>\n",
       "      <td>213</td>\n",
       "      <td>genz.justdoit</td>\n",
       "      <td>705892226323987174500000-12-15</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  shard        channel                           video split\n",
       "1175269  0140186    213  genz.justdoit  705892226323987174500000-12-15   val"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df[joined_df.id == '0140186']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=6): 100%|██████████| 1282242/1282242 [04:01<00:00, 5314.91 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'shard', 'channel', 'video', 'split'],\n",
       "    num_rows: 1282242\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def move_files(sample, src_visual_dir, dest_visual_dir):\n",
    "    id = sample['id']\n",
    "    video = sample['video']\n",
    "    channel = sample['channel']\n",
    "    shard = str(sample['shard']).zfill(4)\n",
    "    split = sample['split']\n",
    "    \n",
    "    src_path = os.path.join(src_visual_dir, channel, video + '.mp4')\n",
    "    os.makedirs(os.path.dirname(src_path), exist_ok=True)\n",
    "    dest_path = os.path.join(dest_visual_dir, split + '_' + shard, id + '.mp4')\n",
    "    os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "    if os.path.exists(src_path):\n",
    "        if not os.path.exists(dest_path):\n",
    "            shutil.move(src_path, dest_path)\n",
    "        else:\n",
    "            os.remove(src_path)\n",
    "\n",
    "\n",
    "ds = Dataset.from_pandas(joined_df)\n",
    "ds.map(\n",
    "    move_files,\n",
    "    fn_kwargs={'src_visual_dir': src_visual_dir, 'dest_visual_dir': dest_visual_dir},\n",
    "    num_proc=6,\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=15):  35%|███▌      | 450772/1282242 [56:24<1:30:38, 152.88 examples/s]moov atom not found\n",
      "Map (num_proc=15):  82%|████████▏ | 1052156/1282242 [2:11:34<28:36, 134.06 examples/s] moov atom not found\n",
      "Map (num_proc=15): 100%|██████████| 1282242/1282242 [2:42:46<00:00, 131.29 examples/s] \n",
      "Filter (num_proc=6): 100%|██████████| 1282242/1282242 [00:03<00:00, 354502.36 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torchvision.io import read_video\n",
    "\n",
    "def check_video(video_path):\n",
    "    try:\n",
    "        read_video(video_path, pts_unit='sec')\n",
    "    except Exception:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_audio(audio_path):\n",
    "    try:\n",
    "        torchaudio.load(audio_path, backend='soundfile')\n",
    "    except Exception:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_sanity(sample, visual_dir, audio_dir):\n",
    "    id = sample['id']\n",
    "    shard = str(sample['shard']).zfill(4)\n",
    "    split = sample['split']\n",
    "\n",
    "    visual_path = os.path.join(visual_dir, split + '_' + shard, id + '.mp4')\n",
    "    sample['visual_status'] = check_video(visual_path)\n",
    "\n",
    "    audio_path = os.path.join(audio_dir, split + '_' + shard, id + '.wav')\n",
    "    sample['audio_status'] = check_audio(audio_path)\n",
    "\n",
    "    return sample\n",
    "\n",
    "ds = Dataset.from_pandas(joined_df)\n",
    "new_ds = ds.map(\n",
    "    check_sanity,\n",
    "    fn_kwargs={'visual_dir': dest_visual_dir, 'audio_dir': dest_audio_dir},\n",
    "    num_proc=15,\n",
    "    load_from_cache_file=False,\n",
    ")\n",
    "new_ds = new_ds.filter(\n",
    "    lambda sample: not sample['visual_status'] or not sample['audio_status'],\n",
    "    num_proc=6,\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tinmoinhat369',\n",
       " 'phanhoangmyvietjetair',\n",
       " 'laihofficial',\n",
       " 'gioiielts98',\n",
       " 'tuquyenlifecoach',\n",
       " 'thedev_dad',\n",
       " 'duyyy.real.channel',\n",
       " 'vtvgiaitriofficial',\n",
       " 'hoangngoctu68',\n",
       " 'duongduongpodcast',\n",
       " 'thangbancaytinikun',\n",
       " 'zing.podcast',\n",
       " 'khanh.sartorial',\n",
       " 'doctorhousing',\n",
       " 'hien.thichhat',\n",
       " 'gaufamilyy',\n",
       " 'thalicvoice',\n",
       " 'dong.congnghe',\n",
       " 'fisc.vn',\n",
       " 'dongthaptv',\n",
       " 'thiendi180119',\n",
       " 'trungthucedu',\n",
       " 'ngao_bao',\n",
       " 'nguoilamphim69',\n",
       " 'kenh14specialvn',\n",
       " 'saigonteu',\n",
       " 'madisonmediagroup',\n",
       " 'truyenthongkhangofficial',\n",
       " 'quynhcuaneee',\n",
       " 'thayqueo',\n",
       " 'vivodio',\n",
       " 'mcnguyenkhang',\n",
       " 'henantrua.mcv',\n",
       " 'mcvtop.mcv',\n",
       " 'longkhoahoc',\n",
       " 'markusnguyen37',\n",
       " 'pcm.studio',\n",
       " 'thuyle2000',\n",
       " 'duyluandethuong',\n",
       " 'gearvn.store',\n",
       " 'nonkhanran',\n",
       " 'vietsuccess',\n",
       " 'luonganhmyy',\n",
       " 'tungbtkhoinghiep',\n",
       " 'tanab.ne',\n",
       " 'vuongtuhoayogi',\n",
       " 'leo.cuong',\n",
       " 'huydao',\n",
       " 'dangdocgiday',\n",
       " 'radiotamsu03',\n",
       " 'dangthuhaf',\n",
       " 'hocvientommy',\n",
       " 'haitrieucareer',\n",
       " 'lepthelittlekid',\n",
       " 'fptlongchau',\n",
       " 'syhuyvuituoi',\n",
       " 'nkhanhm2605',\n",
       " 'unofficiallykyky',\n",
       " 'metv.tiktok',\n",
       " 'ggstravel.khamphanhatban',\n",
       " 'minhtinhday',\n",
       " 'ha_hips',\n",
       " 'gasachh',\n",
       " 'dyhayho',\n",
       " 'vococenter_official',\n",
       " 'suckhoegenz',\n",
       " 'makebelieveshow',\n",
       " 'meowamnhac',\n",
       " 'neko.land23',\n",
       " 'daothinhvuongofficial255',\n",
       " 'hanquangdu',\n",
       " 'vn.joboko',\n",
       " 'dhcvietnam.com.vn',\n",
       " 'vatvostudio',\n",
       " 'luongngo.lifecoach',\n",
       " 'hoaquynh0000',\n",
       " 'sharktankvn',\n",
       " 'petjoy_chamsocthucung',\n",
       " 'lamkhoinghiep',\n",
       " '_sunnytarot_',\n",
       " 'thangmucbang',\n",
       " 'drchubbyderma',\n",
       " 'thansohocdinhhuong369',\n",
       " 'kienkhongngu_official',\n",
       " 'sunhuynn',\n",
       " 'phuongcongnghe',\n",
       " 'giaolocamxuc.beeent',\n",
       " 'tranquangtien164',\n",
       " 'nguyen2hoang2long',\n",
       " 'vinhvatvofake',\n",
       " 'trieuvandeptrai',\n",
       " 'vothailamleo',\n",
       " 'namkechuyenma',\n",
       " 'linhthaiofficial',\n",
       " 'nhuantamlinh',\n",
       " 'luatsubinh',\n",
       " 'marketingthucchien',\n",
       " 'find.forward',\n",
       " 'hoangreaction',\n",
       " 'tizidichlep.official',\n",
       " 'snoop.pi',\n",
       " 'dtn.tuoidaythi',\n",
       " 'innerspacevn',\n",
       " 'weshare.asia',\n",
       " 'earthlovers1111',\n",
       " 'dongocthien_hip',\n",
       " 'mixximuse0305',\n",
       " 'thanhhoctaichinh',\n",
       " 'ntcong5',\n",
       " 'hantuyentech',\n",
       " 'mcmisthy',\n",
       " 'hitmaker.talkshow',\n",
       " 'truesmart.vn',\n",
       " 'vybarnouin',\n",
       " 'hqbt_laodonghanquoc',\n",
       " 'wesleyn313',\n",
       " 'tamsuconggiao',\n",
       " 'nhitho2000',\n",
       " 'sebt.ccs',\n",
       " 'nguyenphuonghuyen_tsh',\n",
       " 'hatdecuoi75',\n",
       " 'realpewpew',\n",
       " 'vtv4go',\n",
       " 'phamnguyenanhtu38h1',\n",
       " 'truyd',\n",
       " 'phaminhiu',\n",
       " 'onlycofficial',\n",
       " 'haiichieu',\n",
       " 'toiyeuvietnam1975',\n",
       " 'son.me.hoc',\n",
       " 'huynhduykhuongofficial',\n",
       " 'hochoimoingaymoi',\n",
       " 'vtcnow',\n",
       " 'cudau8',\n",
       " 'phamcu95',\n",
       " 'sieusaobongda09',\n",
       " 'duocsyduythuc90',\n",
       " 'nguyenque.lifecoach',\n",
       " 'fqa.mp5',\n",
       " 'phamcanhlinh',\n",
       " 'xuan_affiliate',\n",
       " 'quankhonggo',\n",
       " 'nhungvahung',\n",
       " 'phieunoinhieu',\n",
       " 'topcv',\n",
       " 'linh.gb',\n",
       " 'kobe.media79',\n",
       " 'spiderumcareerguide',\n",
       " 'tan.sualaptop',\n",
       " 'dotoearn',\n",
       " 'thongtruyentin',\n",
       " 'paulduongcanada',\n",
       " 'quynhnhu.lifecoach',\n",
       " 'dieuhoalanggo',\n",
       " 'kenjinguyendinh',\n",
       " 'hunghuynhdaotao',\n",
       " 'thehoangwork',\n",
       " 'msngan.panda',\n",
       " 'yoursupp.vn',\n",
       " 'minh.lecong',\n",
       " 'adminkhaofficial',\n",
       " 'ngantalk',\n",
       " 'vyviqng',\n",
       " 'dsnhidong',\n",
       " 'iiiiphone',\n",
       " 'love_and_maturity',\n",
       " 'ngocyakultinvesting',\n",
       " 'thayleodeptrai',\n",
       " 'hongtotheheart',\n",
       " 'gwynethtarot777',\n",
       " 'tntamnguyen92',\n",
       " 'phammaihuong.pmh',\n",
       " 'ngocbinhtamly',\n",
       " 'taiphen',\n",
       " 'htx.tienbo',\n",
       " 'neyakowo',\n",
       " 'datio89',\n",
       " 'thanhdaunguyen3',\n",
       " 'mtsmart.vn',\n",
       " 'fpteduchill',\n",
       " 'roseway68',\n",
       " 'kieu06011993',\n",
       " 'vietargue',\n",
       " 'xangthuonghieu1',\n",
       " 'maiivi8',\n",
       " 'langhoa.workout',\n",
       " 'vantoi.calis',\n",
       " 'khanhvyccf',\n",
       " 'ducreaction',\n",
       " 'tkventuresvn',\n",
       " 'nawngs.official',\n",
       " 'vietcetera_',\n",
       " 'mountain_nguyen',\n",
       " 'phamquyet15121',\n",
       " 'langmaster_entertainment',\n",
       " 'khatienganh',\n",
       " 'nguyenthu.official',\n",
       " 'duongwiki',\n",
       " 'sangsang2x',\n",
       " 'danchoihetao',\n",
       " 'mixigaming',\n",
       " 'risingvietnam.podcast',\n",
       " 'hieutheconsul',\n",
       " 'soncalltech',\n",
       " 'naniosaka',\n",
       " 'vtv24news',\n",
       " 'the.innovators',\n",
       " 'theinfluencer.vn',\n",
       " 'phongthuythuctam',\n",
       " 'vttm_official',\n",
       " 'tinesomot',\n",
       " 'ngatpronlp',\n",
       " 'tu_nguyen_it',\n",
       " 'hungkhucc',\n",
       " 'mitaminhtan',\n",
       " 'kienthanhle90',\n",
       " 'thanh.nv',\n",
       " 'ngominhtuan.official',\n",
       " 'thuuyendaylight',\n",
       " '_celine_nguyen',\n",
       " 'tunggg.pham',\n",
       " 'tinhlong123',\n",
       " 'homeenglishvn',\n",
       " 'virussvn',\n",
       " 'dangbeo9',\n",
       " 'sonapple88',\n",
       " 'mcanhphuong',\n",
       " 'dinovux',\n",
       " 'minhminhhuongzai',\n",
       " 'huuthinhbs',\n",
       " 'the.tri.way',\n",
       " 'marketingcungadam',\n",
       " 'datphinguyen',\n",
       " 'onhadocsach',\n",
       " 'digistockvn',\n",
       " 'duocsythaophan',\n",
       " 'nqs.kinhte',\n",
       " 'vuilenreview',\n",
       " 'chualanhporn',\n",
       " 'ph.khg',\n",
       " 'quoctruong1988',\n",
       " 'truongphuongne',\n",
       " 'insidethebox.cchn',\n",
       " 'nhansohochieuminh',\n",
       " 'mcworld_daotaokynangmem',\n",
       " 'linhmayy2003',\n",
       " 'minhxinchao',\n",
       " 'duyennguyenkd',\n",
       " 'dr.ngomonghung',\n",
       " 'nguyencanhluan',\n",
       " 'thegeomedic',\n",
       " 'dc.podcast',\n",
       " 'nmc.act',\n",
       " 'tranle.phunu30cong',\n",
       " 'otingting_networks',\n",
       " 'linhmayy03',\n",
       " 'trananhtu249',\n",
       " 'maggiemaggievn',\n",
       " 'duyentuban',\n",
       " 'trumdidong.vn',\n",
       " 'mioilami',\n",
       " 'ruto1009',\n",
       " '_thangtaipei_',\n",
       " 'kich.nghe',\n",
       " 'nhile_anne92',\n",
       " 'pphicoach',\n",
       " 'mai_luong_tsh',\n",
       " 'lantechvn',\n",
       " 'taylortichcuc',\n",
       " 'lenkangoo',\n",
       " 'bietduladuu',\n",
       " 'anthonyngofficial',\n",
       " 'hanhchiase.xaykenh',\n",
       " 'hoangmanh8383',\n",
       " 'sitcomtaichinh',\n",
       " 'camvothuat',\n",
       " 'giangkechuyen',\n",
       " 'phuongnamcomedian',\n",
       " 'g84lebichngoc',\n",
       " 'sabrina.uyenluu',\n",
       " 'hiubokho',\n",
       " 'wingmanvn',\n",
       " 'taotechvn',\n",
       " 'luatsux',\n",
       " 'phucmapvlog',\n",
       " 'lydapotato',\n",
       " 'dicungdat',\n",
       " 'remind.ne',\n",
       " 'haluatsu',\n",
       " 'naiverosie',\n",
       " 'quang.tm',\n",
       " 'jaynguyen1101',\n",
       " 'huetran_taydanang',\n",
       " 'linhhoatam11',\n",
       " 'anphat.official',\n",
       " 'withvung',\n",
       " 'dungbanvang',\n",
       " 'chill_with_dan',\n",
       " 'giangoivlog',\n",
       " 'ddttam',\n",
       " 'anratot102',\n",
       " 'rose.ng_',\n",
       " 'tieuthu.chanrau',\n",
       " 'macyennhu',\n",
       " 'saigonspringroll',\n",
       " 'dyxahmazl7at',\n",
       " 'behindthebeauty_zstudio',\n",
       " 'binyetvlog',\n",
       " 'quyquy_2',\n",
       " 'bamboocareers',\n",
       " 'bacsicaohuuthinh',\n",
       " 'hungdidu1907',\n",
       " 'chinhchualon',\n",
       " 'thaihoang_huongnghiep',\n",
       " 'nguyenquynhnaricantho',\n",
       " 'thvl24news',\n",
       " 'behomethansohoc7',\n",
       " 'ngocvanw',\n",
       " 'genz.justdoit',\n",
       " 'vtvthoitiet',\n",
       " 'tamtinhmebim.mcv',\n",
       " 'lifecoachtuean',\n",
       " 'tuan_linh912k',\n",
       " 'nguyenanhtuan.official']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_df = new_ds.to_pandas()\n",
    "miss_df['channel'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from datasets import load_dataset\n",
    "from torchvision.io import read_video\n",
    "\n",
    "def get_num_frames(sample: dict, visual_dir: str, audio_dir: str, split: str):\n",
    "    video_path = os.path.join(visual_dir, split + '_' + str(sample['shard']).zfill(4), sample['id'] + '.mp4')\n",
    "    video, _, _ = read_video(video_path, pts_unit='sec', output_format='THWC')\n",
    "    audio_path = os.path.join(audio_dir, split + '_' + str(sample['shard']).zfill(4), sample['id'] + '.wav')\n",
    "    audio, _ = torchaudio.load(audio_path, channels_first=False)\n",
    "    return {\n",
    "        'id': sample['id'],\n",
    "        'shard': sample['shard'],\n",
    "        'fps': sample['fps'],\n",
    "        'sampling_rate': sample['sampling_rate'],\n",
    "        'video_num_frames': video.shape[0],\n",
    "        'audio_num_frames': audio.shape[0],\n",
    "        'transcript': sample['transcript'],\n",
    "    }\n",
    "\n",
    "ds = load_dataset('parquet', data_files=metadata_path, split='train')\n",
    "ds = ds.map(\n",
    "    get_num_frames,\n",
    "    fn_kwargs={\n",
    "        'visual_dir': visual_dir,\n",
    "        'audio_dir': audio_dir,\n",
    "        'split': split,\n",
    "    },\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=False,\n",
    "    remove_columns=['duration'],\n",
    ")\n",
    "ds.to_parquet(os.path.join(os.path.dirname(metadata_path), f'{split}_completed.parquet'))\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theodore/miniconda3/envs/vasr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map (num_proc=4): 100%|██████████| 1025921/1025921 [3:48:38<00:00, 74.78 examples/s]  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1026/1026 [00:00<00:00, 1601.23ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '0264850',\n",
       " 'fps': 25,\n",
       " 'sampling_rate': 16000,\n",
       " 'transcript': 'bất cứ một chút thu hút nào cả có nghĩa rằng là',\n",
       " 'shard': 1,\n",
       " 'video_num_frames': 76,\n",
       " 'audio_num_frames': 48000}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from datasets import load_dataset\n",
    "from torchvision.io import read_video\n",
    "\n",
    "def get_num_frames(sample: dict, visual_dir: str, audio_dir: str, split: str):\n",
    "    video_path = os.path.join(visual_dir, split + '_' + str(sample['shard']).zfill(4), sample['id'] + '.mp4')\n",
    "    video, _, _ = read_video(video_path, pts_unit='sec', output_format='THWC')\n",
    "    audio_path = os.path.join(audio_dir, split + '_' + str(sample['shard']).zfill(4), sample['id'] + '.wav')\n",
    "    audio, _ = torchaudio.load(audio_path, channels_first=False)\n",
    "    return {\n",
    "        'id': sample['id'],\n",
    "        'shard': sample['shard'],\n",
    "        'fps': sample['fps'],\n",
    "        'sampling_rate': sample['sampling_rate'],\n",
    "        'video_num_frames': video.shape[0],\n",
    "        'audio_num_frames': audio.shape[0],\n",
    "        'transcript': sample['transcript'],\n",
    "    }\n",
    "\n",
    "split = 'train'\n",
    "data_dir = '/media/theodore/TRANSCEND/data/vasr'\n",
    "metadata_path = os.path.join(data_dir, 'pretrain', f'{split}.parquet')\n",
    "visual_dir = os.path.join(data_dir, 'visual')\n",
    "audio_dir = os.path.join(data_dir, 'audio')\n",
    "ds = load_dataset('parquet', data_files=metadata_path, split='train')\n",
    "ds = ds.map(\n",
    "    get_num_frames,\n",
    "    fn_kwargs={\n",
    "        'visual_dir': visual_dir,\n",
    "        'audio_dir': audio_dir,\n",
    "        'split': split,\n",
    "    },\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=False,\n",
    "    remove_columns=['duration'],\n",
    ")\n",
    "ds.to_parquet(os.path.join(os.path.dirname(metadata_path), f'{split}_completed.parquet'))\n",
    "ds[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vasr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
